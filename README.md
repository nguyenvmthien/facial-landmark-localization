# ğŸ§  Facial Landmark Localization

## ğŸ“Œ Introduction
This project focuses on the topic of **Facial Landmark Localization** â€“ identifying key characteristic points on the human face. We conduct a survey of previous research and delve into the architecture of **FaceXFormer** â€“ a model that utilizes the Transformer architecture for this task.

In addition to analyzing the original model, we also **pre-train** it on a smaller dataset and apply the **autocast** technique to reduce computational costs.  
The main objective of this project is to understand the structure of FaceXFormer and provide an overview of research in this field.

<p align="center">
  <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTUdlGtalcFqtNUbUP93oZnMf4tCFPQNkFU5g&s" alt="Facial Landmark Example" width="500"/>
</p>

**Short demo our application:** [video](https://drive.google.com/file/d/13LP3xt4v2CmXS9tpAHjZ2PnCrzIYHPpM/view?usp=sharing)
## ğŸ§° Technologies Used

- ğŸ”¹ Python
- ğŸ”¹ PyTorch
- ğŸ”¹ Jupyter Notebook
- ğŸ”¹ Kaggle
- ğŸ”¹ Streamlit


## ğŸ“  Directory Structure

```plaintext
facial-landmark-localization/
â”œâ”€â”€ Evaluate/           # Model evaluation notebooks
â”œâ”€â”€ Papers/             # Research documents
â”œâ”€â”€ Related-works/      # Collection of related works
â”œâ”€â”€ Source/             # Main source code
â”œâ”€â”€ Surveys/            # Methodology overviews
â”œâ”€â”€ planning.md         # Implementation plan
â””â”€â”€ README.md           # Documentation
```

## âš™ï¸ Installation and Usage

### 1. Clone repository

```bash
git clone https://github.com/nguyenvmthien/facial-landmark-localization.git
cd facial-landmark-localization
```

### 2. Create a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate     # macOS/Linux
venv\Scripts\activate        # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run notebooks
Open Jupyter Notebook and run the `.ipynb` files in the `Evaluate/` directory to view the model evaluation results.

## ğŸ“Š Results and Evaluation

Detailed results from training and re-evaluation of the FaceXFormer model are presented in the notebooks within the `Evaluate/` folder.

Experiments focus on the model's learning ability with smaller datasets and the impact of the autocast technique on performance..

## ğŸ“ License

This project is released under the [MIT License](LICENSE).

## ğŸ‘¥ Contributors

- [Thien Nguyen](https://github.com/nguyenvmthien)
- [VÅ© Minh PhÃ¡t](https://github.com/vmphat)
- [thng292](https://github.com/thng292)
- [TrggTin Rio](https://github.com/TrggTin)
